{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host = \"172.16.34.1\", port = \"5432\", user = \"mimic_demo\", password = \"mimic_demo\", database = \"mimic\")\n",
    "cur = conn.cursor()\n",
    "cur.execute('SET search_path to mimciii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the data. Retrieve the social history from mimiciii database and convert it to spaCy format file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc_bin = DocBin()\n",
    "# Define a regular expression pattern to match the social history section\n",
    "#soc_hist_pattern = \"social history:\\s*(.*?)(?:\\.|\\n\\n)\"\n",
    "soc_hist_pattern = \"social history:\\s*(.*?)(?=\\n{2,}|$)\"\n",
    "#soc_hist_pattern = \"social history:\\s*\\n*\\s*(.*?)(?:\\.|\\n\\n)\" #work for rowid12\n",
    "#soc_hist_pattern = \"social history:(.+?)\\\\\\\\n\\\\\\\\n\"\n",
    "#soc_hist_pattern = r\"social\\s+\\s*:.*?(?=\\n\\n|\\n\\s*\\w+\\s*:|$)\"\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "annotation_dict = {}\n",
    "for index, row in train_data.iterrows():\n",
    "    row_id = row['row_id']\n",
    "    start = row['start']\n",
    "    end = row['end']\n",
    "    sbdh = row['sbdh']\n",
    "    if row_id not in annotation_dict:\n",
    "        annotation_dict[row_id] = []\n",
    "    annotation_dict[row_id].append({'start': start, 'end': end, 'sbdh': sbdh})\n",
    "# Iterate through each row_id in the annotation dictionary\n",
    "for row_id, annotations in annotation_dict.items():\n",
    "\n",
    "    query = f\"\"\"SELECT text FROM mimiciii.noteevents WHERE row_id = {row_id};\"\"\"\n",
    "    cur.execute(query)\n",
    "    text = cur.fetchone()[0]\n",
    "\n",
    "    # Process the text using the spaCy pipeline\n",
    "    doc = nlp(str(text))\n",
    "    match = re.search(soc_hist_pattern, text,re.IGNORECASE | re.DOTALL)\n",
    "    soc_hist_text = match.group(1).strip() \n",
    "    start_char, end_char = match.span(1)\n",
    "    doc_soc = nlp(soc_hist_text)\n",
    "    ents = []\n",
    "    for annotation in annotations:\n",
    "        start = annotation['start']\n",
    "        end = annotation['end']\n",
    "        sbdh = annotation['sbdh']\n",
    "        token_selected = None\n",
    "\n",
    "        token_start_pos = start - start_char\n",
    "        token_end_pos = end - start_char\n",
    "        token_selected = soc_hist_text[token_start_pos:token_end_pos]\n",
    "        if token_selected:\n",
    "            span = doc_soc.char_span(token_start_pos, token_end_pos, sbdh)\n",
    "            if span is not None:\n",
    "                ents.append(span)\n",
    "                \n",
    "    indices = set()\n",
    "    non_overlapping_ents = []\n",
    "    for ent in ents:\n",
    "        s, e = ent.start_char, ent.end_char\n",
    "        if s not in indices and e not in indices:\n",
    "            non_overlapping_ents.append(ent)\n",
    "            indices.update(range(s, e))\n",
    "\n",
    "    doc_soc.ents = non_overlapping_ents        \n",
    "    doc_bin.add(doc_soc)\n",
    "doc_bin.to_disk(\"./data.spacy\")  \n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "doc_list = list(doc_bin.get_docs(nlp.vocab))\n",
    "\n",
    "random.shuffle(doc_list)\n",
    "train_size = int(len(doc_list) * 0.8)\n",
    "\n",
    "train_docs = []\n",
    "test_docs = []\n",
    "for doc in doc_list[:train_size]:\n",
    "    train_docs.append(doc)\n",
    "for doc in doc_list[train_size:]:\n",
    "    test_docs.append(doc)\n",
    "\n",
    "train_bin = DocBin(docs=train_docs)\n",
    "test_bin = DocBin(docs=test_docs)\n",
    "\n",
    "train_bin.to_disk(\"train.spacy\")\n",
    "test_bin.to_disk(\"test.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
